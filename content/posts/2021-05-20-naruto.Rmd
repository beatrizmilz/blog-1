---
title: "Web scraping naruto"
author: ["Beatriz Milz"] 
date: '2021-05-20'
categories: ["tutoriais"] 
tags: ["web scraping", "faxina", "purrr", "rvest"]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, message = FALSE, warning = FALSE)
```

Alguns animes tem muitos *fillers*, que são episódios que não se baseiam na história original, e não agregam na história principal. Muitas vezes parece uma **encheção de linguiça** mesmo, contendo diversos episódios em sequência que não contribuem com a história que estamos acompanhando.

Naruto é um caso onde existem muuuitos fillers! Então eu pulo esses episódios sem dó, usando a [Lista de episódios de Naruto Shippuden](https://pt.wikipedia.org/wiki/Lista_de_epis%C3%B3dios_de_Naruto_Shippuden) disponível no Wikipédia.

O objetivo deste post é apresentar uma forma de importar estes dados para o R, para que a gente ~~não precise acessar toda hora a página do wikipedia~~ consiga fazer uma visualização da distribuição de episódios fillers ao longo dos 500 episódios do anime! Vamos lá, *dattebayo*!

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics("https://media.giphy.com/media/ohT97gdpR40vK/source.gif")
```

## Coleta de dados com Web Scraping

Vamos usar uma técnica chamada *web scraping*, que é baseada em raspar informações de páginas de internet. Primeiro, precisamos buscar o código HTML referente à página do Wikipédia que queremos raspar as informações sobre os episódios de Naruto Shippuden:

```{r}
# Criando um objeto chamado "url_wiki", que contém a url da página do wikipedia
url_wiki <-
  "https://pt.wikipedia.org/wiki/Lista_de_epis%C3%B3dios_de_Naruto_Shippuden"

# Lendo o código html referente à página do wikipedia
# E salvando em um objeto chamado wikipedia_html
wikipedia_html  <- rvest::read_html(url_wiki)
```

O que o objeto `wikipedia_html` contém?

```{r}
wikipedia_html
```

Esse objeto apresenta o código HTML referente à página que queremos raspar! 

### Buscando informações sobre a primeira temporada

Agora precisamos descobrir como acessar as informações que queremos. Olhando a página, podemos ver que os dados de cada temporada estão apresentados em uma tabela diferente. Vamos tentar primeiramente buscar as informações para a tabela referente à primeira temporada, e quando este código estiver funcionando bem, podemos adaptar o código para buscar os dados das outras temporadas! 

Estou utilizando o navegador Google Chrome, e esse navegador tem uma opção que ajuda muito a explorar o código: o inspetor de elementos! Para acessar essa ferramenta, você pode usar o atalho `Ctrl` + `Shift` + `C`, ou clicando no menu superior: "Visualizar" > "Desenvolvedor" > "Inspecionar elementos". Caso você utilize outro navegador, recomendo que procure o equivalente ao inspetor de elementos deste navegador.

Ao acessar o inspetor de elementos, podemos navegar com o cursor e conseguir visualizar o código equivalente a essa parte da página. Uma forma de buscar conteúdos dentro do HTMl é utilizando o `XPath`. Na imagem a seguir, é possível ver que selecionei a tabela referente à primeira temporada, e ao apertar o código na área Elements com o botão direito do mouse, é possível copiar o `XPath` navegando em "Copy" > "Copy XPath":


```{r echo=FALSE, fig.align='center'}
knitr::include_graphics("https://i.ibb.co/3rB68pB/inspetor-de-elementos.png")
```

O `XPath` copiado é: `//*[@id="mw-content-text"]/div[1]/table[4]`. Com isso, podemos usar algumas funções para acessar os conteúdos da tabela, e buscar o conteúdo da tabela:

```{r}
# Carregando o pipe do pacote magrittr
library(magrittr, include.only = "%>%")

# Podemos buscar o conteúdo com o xpath, 
# e as tabelas que estão presentescom a função html_table()
tabela <- "https://pt.wikipedia.org/wiki/Lista_de_epis%C3%B3dios_de_Naruto_Shippuden" %>%
  rvest::read_html() %>%
  rvest::html_node(xpath = '//*[@id="mw-content-text"]/div[1]/table[4]') %>% 
  rvest::html_table()

```

Vamos observar essa tabela referente à primeira temporada: ela contém algumas colunas repetidas, e existe mais de uma linha com informações para o mesmo episódio. Será necessário fazer uma leve **faxina de dados** antes de analisar os dados! 

```{r echo=TRUE}
dplyr::glimpse(tabela)
```

Antes de avançarmos, vamos fazer uma pré-faxina leve, definindo quais colunas iremos manter no final: número de temporada, número do episódio, título original do episódio e a data de estreia. 

```{r echo=TRUE}
tabela %>% 
  # limpar os nomes das variáveis
  janitor::clean_names() %>% 
  # reorganizando quais colunas vamos querer manter
  dplyr::transmute(
      n_temporada = 1,
      n_episodio = as.character(no),
      titulo_episodio = titulo_original,
      data_de_estreia
    ) %>% 
  dplyr::glimpse()
```
Já está um pouco mais claro o que a base contém, né?


### Buscando informações de todas as temporadas!

Na etapa anterior, conseguimos buscar as informações para uma temporada. Podemos criar uma função para buscar as informações de outras temporadas também!

Descobri olhando as tabelas das outras tempoaras que o `XPath` segue o mesmo padrão, alterando apenas o número ao final. Isso será um argumento na função, chamado `n_tabela`. O outro argumento é o número da temporada: `n_temporada`.

```{r}
buscar_tabela <- function(n_tabela, n_temporada) {
  "https://pt.wikipedia.org/wiki/Lista_de_epis%C3%B3dios_de_Naruto_Shippuden" %>%
  rvest::read_html() %>%
  rvest::html_node(xpath = glue::glue('//*[@id="mw-content-text"]/div[1]/table[{n_tabela}]')) %>% 
  rvest::html_table() %>% 
  # limpar os nomes das variáveis
  janitor::clean_names() %>% 
  # reorganizando quais colunas vamos querer manter
  dplyr::transmute(
      n_temporada,
      n_episodio = as.character(no),
      titulo_episodio = titulo_original,
      data_de_estreia
    )
}
```

Os números ao final do `XPath` se iniciam no número 4, e são incrementados de 2 em 2. Portanto, os `XPath` são organizados dessa forma:

  - Temporada 1: `//*[@id="mw-content-text"]/div[1]/table[4]`
  - Temporada 2: `//*[@id="mw-content-text"]/div[1]/table[6]`
  - Temporada 3: `//*[@id="mw-content-text"]/div[1]/table[8]`
  - ......
  - Temporada 20: `//*[@id="mw-content-text"]/div[1]/table[42]`

Portanto podemos criar uma sequência com a função `seq()`, para posteriormente utilizar para buscar todas as tabelas de uma vez!

```{r}
tabela_temporadas <- seq(from = 4, to = 42, by = 2)
```


```{r cache=TRUE}
tabela_suja <-
  purrr::map2_dfr(tabela_temporadas, 1:20, buscar_tabela)
```

```{r}
dplyr::glimpse(tabela_suja)
```



## Faxina


## Visualização


## Naruto Shippuden

```{r}
url_wiki <-
  "https://pt.wikipedia.org/wiki/Lista_de_epis%C3%B3dios_de_Naruto_Shippuden"

wikipedia_page  <- rvest::read_html(url_wiki)

buscar_tabela <- function(n_tabela, n_season) {
  rvest::html_node(
    wikipedia_page,
    xpath = glue::glue('//*[@id="mw-content-text"]/div[1]/table[{n_tabela}]')
  ) |> 
    rvest::html_table() |> 
    janitor::clean_names() |> 
    dplyr::transmute(
      temporada = n_season,
      n_ep = as.character(no),
      titulo = titulo_original,
      data_de_estreia
    )
  }

tabela_temporadas <- seq(4, 42, by = 2)

tabela_suja <-
  purrr::map2_dfr(tabela_temporadas, 1:20, buscar_tabela)


eps_naruto_shippuden <- tabela_suja  |> 
  tidyr::separate(n_ep, into = c("n_ep", "tipo_episodio"), "\\(") |>
  dplyr::mutate(
    n_ep = readr::parse_number(n_ep),
    data_de_estreia = readr::parse_date(
      data_de_estreia,
      format = "%d de %B de %Y",
      locale = readr::locale("pt")
    ),
    tipo_episodio = stringr::str_replace_all(tipo_episodio, "\\)", "")
  ) |>
  tidyr::drop_na(n_ep) |>
  tibble::rowid_to_column() |>
  dplyr::filter(rowid %% 2 != 0) |>
  dplyr::select(-rowid)  |> 
  dplyr::mutate(tipo_episodio = dplyr::case_when(
    is.na(tipo_episodio) ~ "Canon",
    tipo_episodio == "½filler" ~ "Semi-filler",
    TRUE ~ tipo_episodio
  ))
```


```{r}
head(eps_naruto_shippuden)
```
